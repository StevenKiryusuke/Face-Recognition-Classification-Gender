{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library"
      ],
      "metadata": {
        "id": "n0iuRgP9qzF8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMmcgd9wqrqw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torchvision.models import vgg16  # or resnet50\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import seaborn as sns\n",
        "plt.ion()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GENDER RECOGNITION"
      ],
      "metadata": {
        "id": "8XpNYoLwrA-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Data Preparation"
      ],
      "metadata": {
        "id": "CgPF8nlArF3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/FaceRecognition/Dataset'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.listdir(data_path)\n",
        "\n",
        "if os.path.exists(data_path):\n",
        "  print(f\"Directory found: {data_path}\")\n",
        "  os.listdir(data_path)\n",
        "else:\n",
        "  print(f\"Directory not found: {data_path}\")"
      ],
      "metadata": {
        "id": "KwtZw04YrET6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import os\n",
        " import pandas as pd\n",
        " from PIL import Image\n",
        " import torch\n",
        " from torch.utils.data import Dataset, DataLoader\n",
        " from torchvision import transforms\n",
        " # Path ke dataset utama\n",
        "data_path = '\n",
        "/content/drive/MyDrive/FaceRecognition/Dataset'\n",
        "image folder = os path join(data path 'Images')\n",
        "\n",
        "# Load CSV dan TXT\n",
        "gender_csv = os.path.join(data_path, 'gender_classification.csv')\n",
        "identity_txt = os.path.join(data_path, 'class_identity.txt')\n",
        "identity_df = pd.read_csv(identity_txt, sep=' ', header=None, names=['image_filename', 'identity'])\n",
        "gender_df = pd.read_csv(gender_csv)\n",
        "gender_df['gender'] = gender_df['Male'].map({1: 1, 0: 0})\n",
        "# Validasi file gambar yang memang ada\n",
        "valid_files = set(os.listdir(image_folder))\n",
        "identity_df = identity_df[identity_df['image_filename'].isin(valid_files)].reset_index(drop=True)\n",
        "# format filename dibuat konsisten soalnya file class_identity.txt sama image_filename\n",
        "# dlm folder gak sama, kemungkinan tanpa padding\n",
        "min_len = min(len(identity_df), len(gender_df))\n",
        "identity_df['image_filename'] = identity_df['image_filename'].apply(lambda x: f\"{int(x.split('.')[0]):06}.jpg\")\n",
        "gender_df = gender_df.iloc[:min_len].reset_index(drop=True)\n",
        "combined_df = identity_df.copy()\n",
        "combined_df['gender'] = gender_df['gender']\n",
        "## --- Apply robust filtering *before* the split --\n",
        "#drop baris yg gendernya NaN\n",
        "combined_df = combined_df.dropna(subset=['gender'])\n",
        "##combined_df = pd.merge(identity_df, gender_df[['image_filename', 'gender']], on='image_filename', how='inner')\n",
        "## kalo pake coding ini tanpa bawahnya akan error karena PyTorch CrossEntropyLoss() butuh angka, bukan string.\n",
        "#supaya gendernya dalam bentuk angka (0 atau 1)\n",
        "combined_df = combined_df[combined_df['gender'].isin([0, 1])].reset_index(drop=True)\n",
        "# Convert ke int\n",
        "combined_df['gender'] = combined_df['gender'].astype(int)\n",
        "## --- End of robust filtering --\n",
        "print(\"Cleaned Combined DF:\", combined_df.shape)\n",
        "# Cek hasil\n",
        "print(identity_df.head())\n",
        "print(identity_df.shape)\n",
        "print(combined_df)\n",
        "## note: buat liat semua combined_df pake print(combined_df)\n",
        "## buat filter spesifik file pake combined_df.loc[combined_df['image_filename'].isin([...])]\n",
        "## buat filter dengan condition (misal gender=male) pake combined_df.loc[combined_df['gender'] == 'Male']"
      ],
      "metadata": {
        "id": "TCwEbA6Brltn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# buat cek data adalah label biner (1 untuk Male, 0 untuk Female), dan emang cuma ada 1 kolom 'Male'.\n",
        "# trus ditambahin\n",
        "# gender_df['image_filename'] = gender_df.index.map(lambda x: f\"{x+1:06}.jpg\")\n",
        "# gender_df['gender'] = gender_df['Male'].map({1: 'Male', 0: 'Female'})\n",
        "# supaya bisa merge dengan identity_df. --> buat sambungin label ke filename yang benar\n",
        "# buat balikin ke asal bisa pake\n",
        "# original_gender_df = pd.read_csv(gender_csv)\n",
        "# print(original_gender_df.head())\n",
        "print(gender_df.columns)\n",
        "print(gender_df.head())"
      ],
      "metadata": {
        "id": "OsRspoU2sAqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into train and test sets with a 80:20 ratio\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(combined_df, test_size=0.2, random_state=42)\n",
        "print(f\"Train DF size: {len(train_df)}\")\n",
        "print(f\"Validation DF size: {len(val_df)}\")"
      ],
      "metadata": {
        "id": "19yjWQmqsKN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "zu_jgdjwsROC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        " }\n",
        " class GenderDataset(Dataset):\n",
        "    def __init__(self, dataframe, image_folder_path, transform=None):\n",
        "        # Mengubah self.data menjadi self.dataframe sesuai dengan parameter inisialisasi\n",
        "        self.dataframe = dataframe\n",
        "        self.image_folder_path = image_folder_path\n",
        "        self.transform = transform\n",
        "\n",
        "     def __len__(self):\n",
        "        # Mengembalikan panjang dari self.dataframe\n",
        "        return len(self.dataframe)\n",
        " ## __len__: Mengembalikan jumlah data\n",
        " ## Ini dibutuhkan oleh PyTorch DataLoader untuk mengetahui berapa banyak sample di dataset\n",
        "    def __getitem__(self, idx):\n",
        "        # Mengambil data dari self.dataframe\n",
        "        image_filename = self.dataframe.iloc[idx]['image_filename']  # ambil nama file gambar berdasarkan indeks baris k\n",
        "        gender = self.dataframe.iloc[idx]['gender'] #gender udah guaranteed 0 atau 1\n",
        "        image_path = os.path.join(self.image_folder_path, image_filename) # Gabungkan path folder dan nama file jadi ful\n",
        "        try:\n",
        "          image = Image.open(image_path)\n",
        "          if image.mode != 'RGB': #image convertion technique to RGB here\n",
        "            image = image.convert('RGB')\n",
        "          if self.transform:\n",
        "            image = self.transform(image)\n",
        "          gender_tensor = torch.tensor(int(gender), dtype=torch.long) #Ensure gender is a valid integer (0 or 1) and con\n",
        "        except FileNotFoundError:\n",
        "          print(f\"Warning: Image file not found: {image_path}. Skipping this item.\")\n",
        "          # If returning None, the DataLoader might raise an error.\n",
        "          # A common pattern is to return a dummy sample or filter these out beforehand.\n",
        "          # For simplicity in fixing the NameError, we keep the return None, None but be aware\n",
        "          # this might cause issues later in training if many files are missing.\n",
        "          return None, None\n",
        "        except Exception as e:\n",
        "          print(f\"Warning: Error processing image {image_path}: {e}. Skipping this item.\")\n",
        "           # Similar note as above regarding returning None, None\n",
        "          return None, None\n",
        "        return image, gender_tensor\n",
        " # Use the defined GenderDataset class instead of the undefined FaceDataset\n",
        " # data_transforms is now defined in a previous cell\n",
        " train_dataset = GenderDataset(train_df, image_folder, transform=data_transforms['train'])\n",
        " val_dataset = GenderDataset(val_df, image_folder, transform=data_transforms['val'])\n",
        " # Filter out None values returned by __getitem__ if there were errors\n",
        " # This is important if you kept the `return None, None` in __getitem__\n",
        " train_dataset = [data for data in train_dataset if data[0] is not None]\n",
        " val_dataset = [data for data in val_dataset if data[0] is not None]\n",
        " train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        " val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        " dataloaders = {'train': train_loader, 'val': val_loader}\n",
        " dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
        " # buat ganti semua gambar jadi format yg diproses model pytorch\n",
        " transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),   #--> model pretrained vgg biasanya input 224x224x3\n",
        "    transforms.ToTensor(),           # ubah pil.image (RGB) jadi tensor dengan shape [3,224,224] inget BGR!!!\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        " ])\n",
        "\n",
        "image_folder_path = os.path.join(data_path, 'Images')\n",
        " # Buat objek Dataset\n",
        "if not train_df.empty:\n",
        "    train_dataset = GenderDataset(train_df, image_folder_path=image_folder_path, transform=transform)\n",
        "else:\n",
        "    print(\"Warning: train_df is empty after splitting and filtering. train_dataset will be empty.\")\n",
        "    train_dataset = GenderDataset(pd.DataFrame(columns=train_df.columns), image_folder_path=image_folder_path, transform\n",
        "if not val_df.empty:\n",
        "    val_dataset = GenderDataset(val_df, image_folder_path=image_folder_path, transform=transform)\n",
        "else:\n",
        "     print(\"Warning: val_df is empty after splitting and filtering. val_dataset will be empty.\")\n",
        "     val_dataset = GenderDataset(pd.DataFrame(columns=val_df.columns), image_folder_path=image_folder_path, transform=tr\n",
        " ## note: pakai os.path.join(data_path, \"images\") bukan data_path+ '/Images' karena lbh robust & lintas platform\n",
        " # Buat DataLoader\n",
        " if len(train_dataset) > 0:\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        " else:\n",
        "    print(\"Warning: train_dataset is empty. train_loader will not be created.\")\n",
        "    train_loader = None # Or handle this case appropriately\n",
        " if len(val_dataset) > 0:\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        " else:\n",
        "    print(\"Warning: val_dataset is empty. val_loader will not be created.\")\n",
        "    val_loader = None # Or handle this case appropriately\n",
        " ## note: numworkers buat mengaktifkan multiprocessing saat loading data, buat loading data lebih cepet, terutama kalo tr\n",
        " ## Boleh disesuaikan: num_workers=0 (debug mode), atau num_workers=os.cpu_count() untuk maksimal\n",
        " # Loader dictionary\n",
        " dataloaders = {\n",
        "    'train': train_loader,\n",
        "    'val': val_loader\n",
        " }\n",
        " # Dataset size dictionary\n",
        " dataset_sizes = {\n",
        "    'train': len(train_dataset),\n",
        "    'val': len(val_dataset)\n",
        " }\n",
        " transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(), #Mengubah gambar dari PIL.Image ke format tensor PyTorch.\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # pakai mean & std dari ImageNet\n",
        "                     std=[0.229, 0.224, 0.225])\n",
        " ])"
      ],
      "metadata": {
        "id": "ptakCPP-sP-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture GOOGLENET"
      ],
      "metadata": {
        "id": "Nl-x5FDts2mH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFINE MODEL OPTMIZER DAN CRITERION (LOSS FUNCTION)\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "model = models.googlenet()\n",
        "model.fc = nn.Linear(1024, 2)  # 1024 adalah output default GoogLeNet, hanya 2 label: male dan female\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "## buat kirim ke GPU\n",
        "##device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "##model = model.to(device)"
      ],
      "metadata": {
        "id": "WQTq5ij8s32m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "ORrhA8aOs-O1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, use_gpu=True, num_epochs=10):\n",
        "    device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
        "    model.to(device)\n",
        "    train_acc_list = []\n",
        "    val_acc_list = []\n",
        "    #buat full loop training\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "        print(\"-\" * 20)\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()  #Loop kedua: bedain fase training dan validasi.\n",
        "            running_loss = 0.0 #Variabel untuk menyimpan total loss dan jumlah prediksi benar per epoch.\n",
        "            correct = 0\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()  #buat reset gradien dari batch sebelumnya\n",
        "                with torch.set_grad_enabled(phase == 'train'): #nyalain gradien pas training aja, bukan val\n",
        "                    outputs = model(inputs)   #forward pass --> hasil dari prediksi model\n",
        "                    # Access the main output tensor from the GoogLeNetOutputs object\n",
        "                    # GoogLeNet returns a named tuple, access the main logits here.\n",
        "                    # Depending on the torchvision version, it could be outputs.logits or outputs[0]\n",
        "                    # Accessing as outputs[0] is generally safer for compatibility.\n",
        "                    # FIX: Changed models.googlenet.GoogLeNetOutputs to models.GoogLeNetOutputs\n",
        "                    if isinstance(outputs, models.GoogLeNetOutputs):\n",
        "                        logits = outputs.logits\n",
        "                    else:\n",
        "                        logits = outputs\n",
        "                    loss = criterion(logits, labels) #hitung selisih prediksi vs label\n",
        "                    _, preds = torch.max(logits, 1) #ambil prediksi skor tertinggi untuk klasiifikasi\n",
        "                    if phase == 'train':\n",
        "                        loss.backward() #buat hitung gradien\n",
        "                        optimizer.step() #update bobot model sesuai gradien\n",
        "                running_loss += loss.item() * inputs.size(0)  #Tambah loss batch ke running_loss.\n",
        "                correct += torch.sum(preds == labels.data) #hitung brp prediksi benar dan tmbh ke correct\n",
        "            #hitung loss rata2 dan akurasi buat semua data di fase train/val\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = correct.double() / dataset_sizes[phase]\n",
        "            #tampilkan hasil loss & akurasi di console.\n",
        "            print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "            if phase == 'train':\n",
        "                train_acc_list.append(round(epoch_acc.item() * 100, 1))\n",
        "            else:\n",
        "                val_acc_list.append(round(epoch_acc.item() * 100, 1))\n",
        "    print(\"\\ntrain_acc =\", train_acc_list)\n",
        "    print(\"test_acc  =\", val_acc_list)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Buang semua baris dengan NaN\n",
        "combined_df = combined_df.dropna(subset=['gender'])\n",
        "\n",
        "# Pastikan hanya angka 0 atau 1\n",
        "combined_df = combined_df[combined_df['gender'].isin([0, 1])]\n",
        "combined_df['gender'] = combined_df['gender'].astype(int)\n",
        "# Reset index\n",
        "combined_df = combined_df.reset_index(drop=True)\n",
        "print(\"Cleaned Combined DF:\", combined_df.shape)"
      ],
      "metadata": {
        "id": "Uk8hJ-NptCIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DEFINE FUNGSI TRAIN\n",
        "use_gpu = torch.cuda.is_available()\n",
        "print(f\"Using GPU: {use_gpu}\")\n",
        "model = train_model(model, dataloaders, dataset_sizes, criterion, optimizer, use_gpu, 10)"
      ],
      "metadata": {
        "id": "mDVc1OGstePR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PAKAI DATA AUGMENTATION KARENA OVERFITTING"
      ],
      "metadata": {
        "id": "610BiUSOtlyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),  # opsional\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        " ])\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        " ])\n",
        "model = models.googlenet(pretrained=True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "RcShZ-QDtg52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn  #GoogLeNet butuh layer classifier yang disesuaikan\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "train_dataset = GenderDataset(train_df, image_folder, transform=train_transform)\n",
        "val_dataset = GenderDataset(val_df, image_folder, transform=val_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "dataloaders = {'train': train_loader, 'val': val_loader}\n",
        "dataset_sizes = {\n",
        "    'train': len(train_dataset),\n",
        "    'val': len(val_dataset)\n",
        "}\n",
        "model = train_model(model, dataloaders, dataset_sizes, criterion, optimizer, use_gpu, 10)"
      ],
      "metadata": {
        "id": "CcQ24oHdt0Z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import torch\n",
        "import numpy as np\n",
        "def evaluate_model(model, test_loader, target_labels=['Female', 'Male']):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=target_labels))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(all_labels, all_preds))\n",
        "    return all_labels, all_preds\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "vwMtvmu5t7_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_row = combined_df.iloc[0]\n",
        "# Path gambar\n",
        "image_folder = os.path.join(data_path, 'Images')\n",
        "img_path = os.path.join(image_folder, sample_row['image_filename'])\n",
        "# Buka gambar\n",
        "image = Image.open(img_path)\n",
        "# Konversi label numeric ke teks\n",
        "gender_label = 'Male' if sample_row['gender'] == 1 else 'Female'\n",
        "# Tampilkan gambar dan label\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.title(f\"Gender: {gender_label}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p_hCFf4ruI66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i < len(combined_df):\n",
        "      row = combined_df.iloc[i]\n",
        "      img_path = os.path.join(image_folder, row['image_filename'])\n",
        "      image = Image.open(img_path)\n",
        "      gender_label = 'Male' if row['gender'] == 1 else 'Female'\n",
        "\n",
        "      ax.imshow(image)\n",
        "      ax.set_title(f\"Gender: {gender_label}\")\n",
        "      ax.axis('off')\n",
        "    else:\n",
        "      break\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l4kiKEHcuSor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "female_df = combined_df[combined_df['gender'] == 0].reset_index(drop=True)\n",
        "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i < len(female_df):\n",
        "      row = female_df.iloc[i]\n",
        "      img_path = os.path.join(image_folder, row['image_filename'])\n",
        "      image = Image.open(img_path)\n",
        "      ax.imshow(image)\n",
        "      ax.set_title(\"Female\")\n",
        "      ax.axis('off')\n",
        "    else:\n",
        "      break\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0QVYdiJzuesM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "female_df = combined_df[combined_df['gender'] == 0].reset_index(drop=True)\n",
        "fig, axes = plt.subplots(3, 4, figsize=(12, 9))  # tampilkan 12 sample\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    row = female_df.iloc[i]\n",
        "    img_path = os.path.join(image_folder, row['image_filename'])\n",
        "    image = Image.open(img_path)\n",
        "    ax.imshow(image)\n",
        "    ax.set_title(\"Female\")\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RfE8nNbJuouZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}